{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data\n",
    "\n",
    "Data dùng trong bài thực hành này gồm chiều dài dọc gân lá ($x_1$) và chiều ngang gân lá ($x_2$) và loại lá ($y$, có giá trị 0 hoặc 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = train['x1'].values\n",
    "x2_train = train['x2'].values\n",
    "y_train = train['label'].values\n",
    "\n",
    "plt.scatter(x1_train[y_train == 0], x2_train[y_train==0])\n",
    "plt.scatter(x1_train[y_train == 1], x2_train[y_train==1])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "valid = pd.read_csv(\"valid.csv\")\n",
    "x1_valid = valid['x1'].values\n",
    "x2_valid = valid['x2'].values\n",
    "y_valid = valid['label'].values\n",
    "plt.scatter(x1_valid[y_valid == 0], x2_valid[y_valid==0])\n",
    "plt.scatter(x1_valid[y_valid == 1], x2_valid[y_valid==1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Binary Logistic Linear Regression\n",
    "Ta muốn dựa vào 2 chiều của lá, phân biệt giữa loại lá 1 và loại lá 2. Cụ thể, với $x = (x_1,x_2, 1)$ là input, ta muốn đoán một phân phối\n",
    "$$ P_\\theta(c|x),c = 0, 1 $$\n",
    "với $\\theta = (\\theta_1, \\theta_2, \\theta_3)$ là tham số.\n",
    "\n",
    "Trong binary losgistic linear regression, ta giả thuyết\n",
    "$$ P_\\theta(c=0|x) = \\frac{1}{1+ e^{-\\theta_1 x_1 - \\theta_2 x_2 - \\theta_3}} = \\frac{1}{1+ e^{-\\theta \\cdot x}} \\text{ và } P_\\theta(c=1|x) = 1 - P_\\theta(c=0|x)$$\n",
    "\n",
    "Giờ cần tìm $\\theta = (\\theta_1, \\theta_2, \\theta_3)$ sao cho \n",
    "$$ L = \\frac{1}{N} \\sum_{x, y} - (1-y) \\log P_\\theta(c=0|x) - y \\log P_\\theta(c=1|x) = \\frac{1}{N} \\sum_{x, y} - (1-y) \\log \\frac{1}{1+ e^{-\\theta \\cdot x}} - y \\log \\frac{e^{-\\theta \\cdot x}}{1+ e^{-\\theta \\cdot x}} $$\n",
    "đạt giá trị nhỏ nhất. \n",
    "\n",
    "Nếu dùng Gradient Descent:\n",
    "$$ \\frac{\\partial L}{\\partial \\theta_1} = \\frac{1}{N} \\sum_{x, y} e^{-\\theta \\cdot x}  \\left( \\frac{1}{1+e^{-\\theta \\cdot x}} - \\frac{y}{e^{-\\theta \\cdot x}}\\right) (-x_1)$$\n",
    "$$ \\frac{\\partial L}{\\partial \\theta_2} = \\frac{1}{N} \\sum_{x, y} e^{-\\theta \\cdot x}  \\left( \\frac{1}{1+e^{-\\theta \\cdot x}} - \\frac{y}{e^{-\\theta \\cdot x}}\\right) (-x_2)$$\n",
    "$$ \\frac{\\partial L}{\\partial \\theta_3} = \\frac{1}{N} \\sum_{x, y} e^{-\\theta \\cdot x}  \\left( \\frac{1}{1+e^{-\\theta \\cdot x}} - \\frac{y}{e^{-\\theta \\cdot x}}\\right) (-1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalization\n",
    "x1_mean = np.mean(x1_train)\n",
    "x1_std = np.std(x1_train)\n",
    "x2_mean = np.mean(x2_train)\n",
    "x2_std = np.std(x2_train)\n",
    "\n",
    "x1_train = (x1_train - x1_mean)/ x1_std\n",
    "x2_train = (x2_train - x2_mean)/ x2_std\n",
    "\n",
    "x1_valid = (x1_valid - x1_mean)/ x1_std\n",
    "x2_valid = (x2_valid - x2_mean)/ x2_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, theta2, theta3 = 0.0, 0.0, 0.0\n",
    "lrn_rate = 0.001\n",
    "n_iters = 300000\n",
    "\n",
    "best_theta = None      #biến để lưu tham số mà có accuracy tốt nhất trên tập valid\n",
    "best_val_acc = -1.0\n",
    "\n",
    "for ii in range(n_iters):\n",
    "    exppp = np.exp(-theta1*x1_train -theta2*x2_train-theta3)\n",
    "    common = exppp*(1/(1+exppp) - y_train/exppp)\n",
    "    dL_dtheta1 = np.mean(common*(-x1_train))\n",
    "    dL_dtheta2 = np.mean(common*(-x2_train))\n",
    "    dL_dtheta3 = np.mean(common*(-1))\n",
    "    theta1 = theta1 - lrn_rate * dL_dtheta1\n",
    "    theta2 = theta2 - lrn_rate * dL_dtheta2\n",
    "    theta3 = theta3 - lrn_rate * dL_dtheta3\n",
    "    \n",
    "    if ii % 10000 == 0:\n",
    "        ## predict\n",
    "        pred_proba_train = 1/(1+np.exp(-theta1*x1_train-theta2*x2_train-theta3))            ## xác suất label 0\n",
    "        train_loss = np.mean(-(1-y_train)*np.log(pred_proba_train) - y_train*np.log(1-pred_proba_train))\n",
    "        train_acc = np.mean(y_train == (pred_proba_train < 0.5).astype(int))                ## convert xác suất đoán đc ra nhãn rồi tính accuracy\n",
    "        \n",
    "        \n",
    "        pred_proba_valid = 1/(1+np.exp(-theta1*x1_valid-theta2*x2_valid-theta3))\n",
    "        valid_loss = np.mean(-(1-y_valid)*np.log(pred_proba_valid) - y_valid*np.log(1-pred_proba_valid))\n",
    "        valid_acc = np.mean(y_valid == (pred_proba_valid < 0.5).astype(int))\n",
    "        \n",
    "        if valid_acc > best_val_acc:\n",
    "            ## lưu tham số tốt nhất\n",
    "            best_val_acc = valid_acc\n",
    "            best_theta = theta1, theta2, theta3\n",
    "        \n",
    "        print(\"Iter {} - loss {:.4f} - acc {:.4f} - val_loss {:.4f} - val_acc {:.4f}\".format(ii, train_loss, train_acc, valid_loss, valid_acc))\n",
    "\n",
    "theta1, theta2, theta3 = best_theta\n",
    "train_acc = np.mean(y_train == (1/(1+np.exp(-theta1*x1_train-theta2*x2_train-theta3)) < 0.5).astype(int))\n",
    "valid_acc = np.mean(y_valid == (1/(1+np.exp(-theta1*x1_valid-theta2*x2_valid-theta3)) < 0.5).astype(int))\n",
    "print(\"Accuracy on train: \", train_acc)\n",
    "print(\"Accuracy on valid: \", valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = np.concatenate([x1_train.reshape(-1,1), x2_train.reshape(-1,1)], axis=-1)\n",
    "X_valid = np.concatenate([x1_valid.reshape(-1,1), x2_valid.reshape(-1,1)], axis=-1)\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Sklearn accuracy on train: \", np.mean(y_train == lr.predict(X_train)))\n",
    "print(\"Sklearn accuracy on valid: \", np.mean(y_valid == lr.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Bài tập\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Multi-class Logistic Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta muốn dựa vào 2 chiều của lá, phân biệt giữa 3 loại lá. Cụ thể, với  $x=(x_1, x_2, 1)$  là input, ta muốn đoán một phân phối\n",
    "$$ P_\\theta(c|x), c=0,1,2 $$\n",
    "\n",
    "Đặt $\\theta_0 = (\\theta_{01}, \\theta_{02}, \\theta_{03}), \\theta_1 = (\\theta_{11}, \\theta_{12}, \\theta_{13})$ và $\\theta_2 = (\\theta_{21}, \\theta_{22}, \\theta_{23})$. Giả thuyết\n",
    "$$ P_\\theta(c|x) = \\frac{e^{\\theta_c \\cdot x}}{\\sum_{c'=0}^2 e^{\\theta_{c'} \\cdot x}},c = 0, 1, 2.$$\n",
    "\n",
    "Gọi $y = (y_0, y_1, y_2)$ là one-hot vector biểu thị loại lá tương ứng với $x$. Ta Tìm các $\\theta$ sao cho\n",
    "$$ L = \\frac{1}{N} \\sum_{x,y} - y_0 \\log P_\\theta(0|x) -  y_1 \\log P_\\theta(1|x) - y_2 \\log P_\\theta(2|x) $$\n",
    "đạt giá trị nhỏ nhất.\n",
    "\n",
    "Tương tự như hưỡng dẫn, hãy viết script giải bài toán trên bằng gradient descent.\n",
    "\n",
    "Đồng thời so sánh kết quả với sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"bt_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1_train = train['x1'].values\n",
    "x2_train = train['x2'].values\n",
    "y_train = train['label'].values\n",
    "\n",
    "plt.scatter(x1_train[y_train == 0], x2_train[y_train==0])\n",
    "plt.scatter(x1_train[y_train == 1], x2_train[y_train==1])\n",
    "plt.scatter(x1_train[y_train == 2], x2_train[y_train==2])\n",
    "\n",
    "plt.figure()\n",
    "valid = pd.read_csv(\"bt_valid.csv\")\n",
    "x1_valid = valid['x1'].values\n",
    "x2_valid = valid['x2'].values\n",
    "y_valid = valid['label'].values\n",
    "\n",
    "plt.scatter(x1_valid[y_valid == 0], x2_valid[y_valid==0])\n",
    "plt.scatter(x1_valid[y_valid == 1], x2_valid[y_valid==1])\n",
    "plt.scatter(x1_valid[y_valid == 2], x2_valid[y_valid==2])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
