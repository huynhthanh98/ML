{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of lab-08.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j411dkkAuSvt"
      },
      "source": [
        "**Lab-08: Backpropagation**\n",
        "\n",
        "Trong bài thực hành này chúng ta sẽ thử cài đặt Backpropagation \n",
        "\n",
        "Ta muốn dựa vào 2 chiều của lá, phân biệt giữa loại lá 1 và loại lá 2. Cụ thể, với $x = (x_1,x_2, 1)$ là input, ta muốn đoán một phân phối\n",
        "    $$ P_\\\\theta(c|x),c = 0, 1 $$\n",
        "với $\\\\theta$ là các tham số\n",
        "Ta mô hình $P_\\theta$ là một neural network có 2 lớp ẩn, mỗi lớp 5 neurons, tức là\\n\",\n",
        "    $$ P_\\\\theta(c|x) = \\\\text{softmax}(\\\\max(0, \\\\max(0, x \\\\cdot W_1 + b_1) \\\\cdot W_2 + b_2) \\\\cdot W_3 + b_3 )$$\n",
        "\n",
        "với $x$ là vector dòng $[[x_1, x_2]]$ kích thước $ 1\\times 2$, $W_1, W_2, W_3$ là các ma trận có kích thước $2 \\times 5, 5 \\times 5, 5 \\times 3$, và $b_1, b_2, b_3$ là các ma trận kích thước $1 \\times 5, 1 \\times 5, 1 \\times 3$.\n",
        "\n",
        "Khi đó $P(c|x)$ là một vector dòng độ dài 3, xem như $P(c|x)= (P_1(c|x), P_2(c|x), P_3(c|x)) = (P(c=0|x), P(c=1|x), P(c=2|x))$\n",
        "Bộ các ma trận $\\\\theta = (W_1, W_2, W_3, b_1, b_2, b_3)$ chính là tham số cần tìm của model. Giờ cần tìm $\\\\theta$ sao cho \n",
        "\n",
        "$$ L = \\frac{1}{N} \\sum_{x,y} - y_0 \\log P_\\theta(0|x) -  y_1 \\log P_\\theta(1|x) - y_2 \\log P_\\theta(2|x) $$\n",
        "\n",
        "đạt giá trị nhỏ nhất với $y = (y_0, y_1, y_2)$ là one-hot vector biểu thị loại lá tương ứng với $x$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRjcNaFBigAx"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zS_ADnTigA3"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzecGvNIigA4"
      },
      "source": [
        "def one_hot_vector(y):\n",
        "    out = np.zeros((y.shape[0], max(y)+1))\n",
        "    for i in range(y.shape[0]):\n",
        "        out[i, y[i]] = 1\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpL3fpASigA5"
      },
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_train.csv\")\n",
        "valid = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_valid.csv\")\n",
        "\n",
        "x1_train = train[\"x1\"].values\n",
        "x2_train = train[\"x2\"].values\n",
        "y_train = train[\"label\"].values\n",
        "\n",
        "x1_valid = valid['x1'].values\n",
        "x2_valid = valid['x2'].values\n",
        "y_valid = valid['label'].values\n",
        "\n",
        "# normalize\n",
        "x1_mean = np.mean(x1_train)\n",
        "x1_std = np.std(x1_train)\n",
        "x2_mean = np.mean(x2_train)\n",
        "x2_std = np.std(x2_train)\n",
        "\n",
        "x1_train = (x1_train - x1_mean)/ x1_std\n",
        "x2_train = (x2_train - x2_mean)/ x2_std\n",
        "\n",
        "x1_valid = (x1_valid - x1_mean)/ x1_std\n",
        "x2_valid = (x2_valid - x2_mean)/ x2_std\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.concatenate([x1_train.reshape(-1,1), x2_train.reshape(-1,1)], axis=1)\n",
        "y_train = one_hot_vector(y_train)\n",
        "\n",
        "X_valid = np.concatenate([x1_valid.reshape(-1,1), x2_valid.reshape(-1,1)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_CidQJtigA7"
      },
      "source": [
        "# initialize\n",
        "W1 = np.random.randn(2,5)\n",
        "W2 = np.random.randn(5,5)\n",
        "W3 = np.random.randn(5,3)\n",
        "\n",
        "b1 = np.random.randn(1,5)\n",
        "b2 = np.random.randn(1,5)\n",
        "b3 = np.random.randn(1,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw8mSDk6igA9"
      },
      "source": [
        "def relu(h):\n",
        "    return np.array([max(0,i) for i in h.reshape(-1)]).reshape(h.shape)\n",
        "\n",
        "def softmax(z):\n",
        "    return np.exp(z)/ np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "\n",
        "def CrossEntropy(o,y):\n",
        "    return - np.sum(np.log(o)*y)\n",
        "\n",
        "ln = 0.001\n",
        "N = y_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLI8EDoigA-"
      },
      "source": [
        "for epochs in range(100000):\n",
        "    # foward\n",
        "    z1 = np.dot(X_train, W1) + b1\n",
        "    o1 = relu(z1)\n",
        "\n",
        "    z2 = np.dot(o1, W2) + b2\n",
        "    o2 = relu(z2)\n",
        "\n",
        "    z3 = np.dot(o2, W3) + b3\n",
        "    o3 = softmax(z3)\n",
        "\n",
        "    # backpropagation\n",
        "    dL_dz3 = 1/len(X_train)*(o3 - y_train) \n",
        "    dL_dW3 = np.dot(o2.T, dL_dz3)    \n",
        "    dL_db3 = np.sum(dL_dz3, axis = 0)\n",
        "\n",
        "\n",
        "    dL_do2 = np.dot(dL_dz3, W3.T)\n",
        "    dL_dz2 = dL_do2.copy()\n",
        "    dL_dz2[z2 < 0] = 0\n",
        "    dL_dW2 = np.dot(o1.T,dL_dz2)\n",
        "    dL_db2 = np.sum(dL_dz2, axis = 0)\n",
        "\n",
        "    dL_do1 = np.dot(dL_dz2, W2.T)\n",
        "    dL_dz1 = dL_do1.copy()\n",
        "    dL_dz1[z1 < 0] = 0\n",
        "    dL_dW1 = np.dot(X_train.T, dL_dz1)\n",
        "    dL_db1 = np.sum(dL_dz1, axis = 0)\n",
        "\n",
        "    W3 -= ln* dL_dW3\n",
        "    b3 -= ln* dL_db3\n",
        "    W2 -= ln* dL_dW2\n",
        "    b2 -= ln* dL_db2\n",
        "    W1 -= ln* dL_dW1\n",
        "    b1 -= ln* dL_db1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmSjKNZpigBA"
      },
      "source": [
        "z1_valid = np.dot(X_valid, W1) + b1\n",
        "o1_valid = relu(z1_valid)\n",
        "\n",
        "z2_valid = np.dot(o1_valid, W2) + b2\n",
        "o2_valid = relu(z2_valid)\n",
        "\n",
        "z3_valid = np.dot(o2_valid, W3) + b3\n",
        "o3_valid = softmax(z3_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHthk1kuigBB",
        "outputId": "95f838d7-1da4-4c5d-9c44-bddaa5d89586"
      },
      "source": [
        "np.sum(np.argmax(o3_valid, axis = 1) == y_valid)/ y_valid.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6233333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSZlBMhnewyH"
      },
      "source": [
        "#Bài Tập\n",
        "1. Từ code demo hãy cài đặt thêm một module để chọn ra được bộ weights sao cho accuracy trên tập validation là tốt nhất.\n",
        "2. Từ bộ dữ liệu bên dưới hãy cài đặt backpropagation cho bài toán phân biệt ung thư vú. Hãy tự chọn số layers và số nodes mà mình cho là thích hợp, cũng như là nêu ra số layers và số nodes của mỗi layer mà mình đã chọn. Tính accuracy trên tập training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1NscLiyVYuPx"
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X = breast_cancer.data  \n",
        "y = breast_cancer.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_mean=np.mean(X_train)\n",
        "X_std=np.std(X_train)\n",
        "\n",
        "X_valid=(X_valid-X_mean)/X_std\n",
        "    X_train=(X_train-X_mean)/X_std"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}